{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run the commands below if imports fail\n",
    "# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
    "# !pip install matplotlib --upgrade --quiet\n",
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch,jovian, torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speeds up the ipy notebook intellisense\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "project_name='insurance-linear-regression-pytorch' # will be used by jovian.commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download and explore the data\n",
    "\n",
    "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12182f0fd64b48b7bef0033329f982c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = 'Naman Singhal' # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>25.80200</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>23270.089540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>31.88390</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>7684.523217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>54</td>\n",
       "      <td>male</td>\n",
       "      <td>29.30370</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>11152.334891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>59</td>\n",
       "      <td>male</td>\n",
       "      <td>27.92145</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>13221.279423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>23.86685</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>5730.683666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex       bmi  children smoker       charges\n",
       "160    42  female  25.80200         0    yes  23270.089540\n",
       "1326   42  female  31.88390         0     no   7684.523217\n",
       "544    54    male  29.30370         0     no  11152.334891\n",
       "624    59    male  27.92145         0     no  13221.279423\n",
       "914    33    male  23.86685         2     no   5730.683666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1271 entries, 160 to 827\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1271 non-null   int64  \n",
      " 1   sex       1271 non-null   object \n",
      " 2   bmi       1271 non-null   float64\n",
      " 3   children  1271 non-null   int64  \n",
      " 4   smoker    1271 non-null   object \n",
      " 5   charges   1271 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 69.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us answer some basic questions about the dataset. \n",
    "\n",
    "\n",
    "**Q: How many rows does the dataset have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How many columns doe the dataset have**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What are the column titles of the input variables?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'charges'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'bmi', 'children', 'sex', 'smoker']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = ['age',  'bmi', 'children', 'sex','smoker']\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Which of the input columns are non-numeric or categorical variables ?**\n",
    "\n",
    "Hint: `sex` is one of them. List the columns that are not numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['sex','smoker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What are the column titles of output/target variable(s)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = ['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
    "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column - Charges\n",
      "Minimum Value - 1222.84\n",
      "Maximum Value - 69509.77\n",
      "Average Value - 14411.98\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "print('''Column - Charges\n",
    "Minimum Value - {:.2f}\n",
    "Maximum Value - {:.2f}\n",
    "Average Value - {:.2f}'''.format(min(dataframe.charges),max(dataframe.charges),dataframe.charges.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([270., 239., 195., 183.,  70.,  55.,  45.,  39.,  23.,   9.,  23.,\n",
       "         31.,  27.,  26.,  21.,   9.,   1.,   1.,   2.,   2.]),\n",
       " array([ 1222.842551  ,  4637.18875   ,  8051.53494899, 11465.88114798,\n",
       "        14880.22734698, 18294.57354598, 21708.91974497, 25123.26594397,\n",
       "        28537.61214296, 31951.95834196, 35366.30454095, 38780.65073995,\n",
       "        42194.99693894, 45609.34313794, 49023.68933693, 52438.03553593,\n",
       "        55852.38173492, 59266.72793392, 62681.07413291, 66095.4203319 ,\n",
       "        69509.7665309 ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataframe['charges'],bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset for training\n",
    "\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[42.     , 25.802  ,  0.     ,  0.     ,  1.     ],\n",
       "        [42.     , 31.8839 ,  0.     ,  0.     ,  0.     ],\n",
       "        [54.     , 29.3037 ,  0.     ,  1.     ,  0.     ],\n",
       "        ...,\n",
       "        [40.     , 24.6962 ,  1.     ,  0.     ,  0.     ],\n",
       "        [55.     , 36.58355,  3.     ,  1.     ,  0.     ],\n",
       "        [36.     , 27.18425,  1.     ,  1.     ,  1.     ]]),\n",
       " array([[23270.08954  ],\n",
       "        [ 7684.523217 ],\n",
       "        [11152.334891 ],\n",
       "        ...,\n",
       "        [ 7714.136446 ],\n",
       "        [32769.3027995],\n",
       "        [22643.2542475]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = torch.from_numpy(inputs_array)\n",
    "#targets = torch.from_numpy(targets_array)\n",
    "inputs = torch.as_tensor(inputs_array, dtype=torch.float32)\n",
    "targets = torch.as_tensor(targets_array, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1271, 5]), torch.Size([1271, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[42.0000, 25.8020,  0.0000,  0.0000,  1.0000],\n",
       "         [42.0000, 31.8839,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[23270.0898],\n",
       "         [ 7684.5234]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(inputs, targets)\n",
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.15\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_ds, val_ds = random_split(dataset=dataset, lengths=[train_size,val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create data loaders for training & validation.\n",
    "\n",
    "**Q: Pick a batch size for the data loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a batch of data to verify everything is working fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([115, 5])\n",
      "targets: torch.Size([115, 1])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb.shape)\n",
    "    print(\"targets:\", yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Linear Regression Model\n",
    "\n",
    "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
    "\n",
    "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)               # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = F.l1_loss(out, targets)    \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.l1_loss(out, targets)\n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the weights and biases of the model using `model.parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2964, -0.0498,  0.1849, -0.3528,  0.4381]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0486], requires_grad=True)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final commit before we train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model to fit the data\n",
    "\n",
    "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 13900.3115234375}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
    "\n",
    "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 13895.5225\n",
      "Epoch [30], val_loss: 13893.1250\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "lr = 1e-5\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 9692.9014\n",
      "Epoch [40], val_loss: 7972.8438\n",
      "Epoch [60], val_loss: 7614.3555\n",
      "Epoch [80], val_loss: 7550.0859\n",
      "Epoch [90], val_loss: 7536.0605\n"
     ]
    }
   ],
   "source": [
    "epochs = 90\n",
    "lr = 1e-2\n",
    "history2 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7310.5532\n",
      "Epoch [40], val_loss: 7129.0137\n",
      "Epoch [50], val_loss: 7065.7959\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "lr = 1e-1\n",
    "history3 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 6998.4873\n",
      "Epoch [40], val_loss: 6923.9287\n",
      "Epoch [60], val_loss: 6917.3418\n",
      "Epoch [80], val_loss: 6901.1582\n",
      "Epoch [100], val_loss: 6899.1133\n",
      "Epoch [120], val_loss: 6908.2827\n",
      "Epoch [140], val_loss: 6877.7920\n",
      "Epoch [150], val_loss: 6877.0649\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "lr = 0.5\n",
    "history4 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 6866.7051\n",
      "Epoch [40], val_loss: 6868.4297\n",
      "Epoch [60], val_loss: 6862.4326\n",
      "Epoch [80], val_loss: 6862.1216\n",
      "Epoch [100], val_loss: 6862.2822\n",
      "Epoch [120], val_loss: 6859.9219\n",
      "Epoch [140], val_loss: 6863.3735\n",
      "Epoch [160], val_loss: 6856.4932\n",
      "Epoch [180], val_loss: 6859.2373\n",
      "Epoch [200], val_loss: 6855.4736\n",
      "Epoch [220], val_loss: 6859.1621\n",
      "Epoch [240], val_loss: 6847.7515\n",
      "Epoch [260], val_loss: 6852.2939\n",
      "Epoch [280], val_loss: 6848.9658\n",
      "Epoch [300], val_loss: 6845.9927\n",
      "Epoch [320], val_loss: 6843.4736\n",
      "Epoch [340], val_loss: 6845.0366\n",
      "Epoch [360], val_loss: 6843.9814\n",
      "Epoch [380], val_loss: 6842.8057\n",
      "Epoch [400], val_loss: 6844.2393\n",
      "Epoch [420], val_loss: 6840.6807\n",
      "Epoch [440], val_loss: 6839.7529\n",
      "Epoch [460], val_loss: 6835.3301\n",
      "Epoch [480], val_loss: 6832.7759\n",
      "Epoch [500], val_loss: 6834.9370\n",
      "Epoch [520], val_loss: 6830.1309\n",
      "Epoch [540], val_loss: 6838.7070\n",
      "Epoch [560], val_loss: 6831.1919\n",
      "Epoch [580], val_loss: 6835.1699\n",
      "Epoch [600], val_loss: 6825.0542\n",
      "Epoch [620], val_loss: 6821.3975\n",
      "Epoch [640], val_loss: 6826.3633\n",
      "Epoch [660], val_loss: 6820.5742\n",
      "Epoch [680], val_loss: 6821.4365\n",
      "Epoch [700], val_loss: 6820.6265\n",
      "Epoch [720], val_loss: 6825.1641\n",
      "Epoch [740], val_loss: 6825.0435\n",
      "Epoch [760], val_loss: 6824.3428\n",
      "Epoch [780], val_loss: 6817.4277\n",
      "Epoch [800], val_loss: 6813.3452\n",
      "Epoch [820], val_loss: 6811.9072\n",
      "Epoch [840], val_loss: 6810.2319\n",
      "Epoch [860], val_loss: 6808.5654\n",
      "Epoch [880], val_loss: 6807.5347\n",
      "Epoch [900], val_loss: 6808.6826\n",
      "Epoch [920], val_loss: 6798.3403\n",
      "Epoch [940], val_loss: 6811.5928\n",
      "Epoch [960], val_loss: 6807.6309\n",
      "Epoch [980], val_loss: 6809.1875\n",
      "Epoch [1000], val_loss: 6798.8057\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-1\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What is the final validation loss of your model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = 6798.8057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's log the final validation loss to Jovian and commit the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Metrics logged.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.log_metrics(val_loss=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"namansnghl/insurance-linear-regression-pytorch\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/namansnghl/insurance-linear-regression-pytorch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/namansnghl/insurance-linear-regression-pytorch'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(message='val_loss 2',project=project_name,environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Make predictions using the trained model\n",
    "\n",
    "**Q: Complete the following function definition to make predictions on a single input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)                # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([63.0000, 21.0102,  1.0000,  1.0000,  0.0000])\n",
      "Target: tensor([15641.3408])\n",
      "Prediction: tensor([15414.6436])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([57.0000, 39.0716,  0.0000,  1.0000,  0.0000])\n",
      "Target: tensor([22572.8320])\n",
      "Prediction: tensor([11786.8555])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([37.0000, 29.8760,  0.0000,  1.0000,  0.0000])\n",
      "Target: tensor([5064.9673])\n",
      "Prediction: tensor([7147.7544])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you happy with your model's predictions? Try to improve them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(message='Completed', project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
